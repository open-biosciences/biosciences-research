{
  "ragas_version": "0.2.10",
  "python_version": "3.13",
  "llm": {
    "model": "gpt-4.1-mini",
    "temperature": 0,
    "provider": "openai",
    "purpose": "RAG generation and RAGAS evaluation"
  },
  "embeddings": {
    "model": "text-embedding-3-small",
    "dimensions": 1536,
    "provider": "openai",
    "purpose": "Document and query embeddings"
  },
  "retrievers": [
    {
      "name": "naive",
      "type": "dense_vector_search",
      "description": "Baseline dense vector search with OpenAI embeddings",
      "k": 5,
      "distance_metric": "cosine",
      "rerank": false
    },
    {
      "name": "bm25",
      "type": "sparse_keyword",
      "description": "BM25 sparse keyword matching (lexical)",
      "k": 5,
      "rerank": false
    },
    {
      "name": "cohere_rerank",
      "type": "contextual_compression",
      "description": "Cohere rerank-v3.5 with contextual compression",
      "initial_k": 20,
      "top_n": 3,
      "rerank_model": "rerank-v3.5",
      "rerank_provider": "cohere",
      "rerank": true
    },
    {
      "name": "ensemble",
      "type": "hybrid",
      "description": "Ensemble combining dense vector + sparse keyword",
      "dense_k": 5,
      "sparse_k": 5,
      "weights": [
        0.5,
        0.5
      ],
      "components": [
        "naive_dense",
        "bm25_sparse"
      ],
      "rerank": false
    }
  ],
  "evaluation": {
    "golden_testset": "open-biosciences/biosciences-golden-testset",
    "golden_testset_size": 12,
    "source_dataset": "open-biosciences/biosciences-sources",
    "source_dataset_size": 38,
    "metrics": [
      "faithfulness",
      "answer_relevancy",
      "context_precision",
      "context_recall"
    ],
    "timeout_seconds": 360,
    "ragas_run_config": {
      "timeout": 360,
      "max_workers": 4
    }
  },
  "vector_store": {
    "type": "qdrant",
    "collection_name": "biosciences-data-sources",
    "host": "https://1d48094c-93af-4f43-8a71-8ffd45883525.us-west-1-0.aws.cloud.qdrant.io",
    "port": 6333,
    "distance": "cosine",
    "vector_size": 1536
  },
  "skipped": [],
  "notes": [
    "All LLM calls use temperature=0 for determinism",
    "Fine-tuned embeddings out of scope per instructor guidance",
    "Evaluation follows RAGAS 0.2.10 API patterns from session08"
  ],
  "generated_at": "2026-03-01T07:17:51.439160Z",
  "generated_by": "scripts/generate_run_manifest.py",
  "results_summary": {
    "naive": {
      "faithfulness": 0.9392202751403714,
      "answer_relevancy": 0.9603827093149282,
      "context_precision": 0.8775462962728607,
      "context_recall": 0.9666666666666667,
      "average": 0.9359539868487068
    },
    "bm25": {
      "faithfulness": 0.914984851727557,
      "answer_relevancy": 0.9645305178704646,
      "context_precision": 0.8756944444185127,
      "context_recall": 0.9103174603174603,
      "average": 0.9163818185834987
    },
    "ensemble": {
      "faithfulness": 0.9592631941838291,
      "answer_relevancy": 0.9613054326178482,
      "context_precision": 0.8978680476640714,
      "context_recall": 0.9666666666666667,
      "average": 0.9462758352831039
    },
    "cohere_rerank": {
      "faithfulness": 0.9564670456391845,
      "answer_relevancy": 0.9659360653099435,
      "context_precision": 0.9861111110743054,
      "context_recall": 0.9305555555555555,
      "average": 0.9597674443947471
    }
  },
  "data_provenance": {
    "ingest_manifest_id": "ragas_pipeline_f1eb144c-3c06-4354-bf0c-e0f752faedfe",
    "ingest_timestamp": "2026-03-01T06:59:32.140375Z",
    "sources_sha256": "78d5a84e23a949f88f259c8ef8a82179fa85b85218f1af2de467a4b3a466e51a",
    "golden_testset_sha256": "cbd520971dc809cef39b51189b4908c1d719ee8a90eb0d71f708751368e69277",
    "source_pdfs_count": "all",
    "ragas_testset_size": 10
  }
}